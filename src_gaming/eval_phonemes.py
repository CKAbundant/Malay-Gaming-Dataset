"""Functions to perform evaluation for various phonemes set
"""


import logging
import os
import sys
import warnings
from pathlib import Path
from typing import Dict, List

import hydra
import malaya_speech
import pandas as pd
from omegaconf import DictConfig, OmegaConf, open_dict
from pandarallel import pandarallel

sys.path.append(Path(__file__).parents[2].as_posix())

from notebooks.src_eval.metrics_analysis_utils import display_audio, gen_top_bottom
from notebooks.src_eval.metrics_gen_utils import (
    append_alignment_score,
    append_asr,
    append_mcd,
    append_mel_mfcc_path,
    append_wer_cer,
)
from notebooks.src_eval.metrics_plot_utils import append_pca
from src.utils.dataframe_utils import read_from_csv, save_to_csv

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
warnings.filterwarnings("ignore")
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


@hydra.main(config_path="../src_eval", config_name="model_objective_eval.yaml")
def run(cfg: DictConfig) -> pd.DataFrame:
    """Perform evaluation on phoneme set, which has no ground truth.

    Args:
        cfg (DictConfig):
            OmegaConfig Dictionary containing configurable parameters
            for evaluating phonemes.

    Returns:
        output_complete (pd.DataFrame):
            DataFrame appended with ACR, MCD, WER and CER metrics.
    """

    logging.info("Generate metrics...")
    path_dict = {
        "combined": cfg.path.combined_path,
        "gt_wav_dir": cfg.path.gt_wav_dir,
        "gt_mel_dir": cfg.path.gt_mel_dir,
        "gt_mfcc_dir": cfg.path.gt_mfcc_dir,
        "syn_path": cfg.path.syn_path,
        "syn_wav_path": cfg.path.syn_wav_path,
        "syn_mel_dir": cfg.path.syn_mel_dir,
        "syn_mfcc_dir": cfg.path.syn_mfcc_dir,
        "original": cfg.path.test_csv_path,
        "mfcc": cfg.path.test_mfcc_path,
        "acr": cfg.path.test_acr_path,
        "mcd": cfg.path.test_mcd_path,
        "asr": cfg.path.test_asr_path,
        "wer_cer": cfg.path.test_wer_cer_path,
        "complete": cfg.path.test_complete_path,
    }

    mel_mfcc_dict = {
        "sr": cfg.mel_mfcc.sampling_rate,
        "n_fft": cfg.mel_mfcc.n_fft,
        "hop_length": cfg.mel_mfcc.hop_length,
        "win_length": cfg.mel_mfcc.win_length,
        "window": cfg.mel_mfcc.window,
        "power": cfg.mel_mfcc.power,
        "n_mels": cfg.mel_mfcc.n_mels,
        "n_mfcc": cfg.mel_mfcc.n_mfcc,
        "dct_type": cfg.mel_mfcc.dct_type,
        "norm_mfcc": cfg.mel_mfcc.norm_mfcc,
        "lifter": cfg.mel_mfcc.lifter,
    }

    # Initialize pandarallel
    progress_bar = cfg.general.progress_bar
    num_proc = cfg.general.nb_workers
    initialize_pandarallel(progress_bar, num_proc)

    # Load output csv file and configure DataFrame
    output_meta = load_csv(path_dict)

    # Generate mel and mfcc of speech generated by Malaya VITS (ground truth)
    output_mfcc_gt = append_mel_mfcc_path(output_meta, path_dict, mel_mfcc_dict, "gt")

    # Generate mel and mfcc of synthesized speech
    output_mfcc = append_mel_mfcc_path(output_mfcc_gt, path_dict, mel_mfcc_dict)
    save_to_csv(output_mfcc, path_dict["mfcc"])

    # Append Alignment Coverage Ratio (ACR)
    output_acr = append_alignment_score(output_mfcc)
    save_to_csv(output_acr, path_dict["acr"])

    # Append Mel-Ceptral Distortion (MCD)
    output_mcd = append_mcd(output_acr)
    save_to_csv(output_mcd, path_dict["mcd"])

    # Generate transcribed text
    output_asr_syn = append_asr(output_mcd, "syn_transcribed")
    save_to_csv(output_asr_syn, path_dict["asr"])

    # Append Word Error Rate (WER) & Character Error Rate (CER)
    output_wer_cer = append_wer_cer(output_asr_syn, "syn_transcribed")
    save_to_csv(output_wer_cer, path_dict["wer_cer"])

    # Append PCA
    output_complete = append_pca(output_wer_cer)
    save_to_csv(output_complete, path_dict["complete"])

    return output_complete


def eval_phon(cfg: DictConfig) -> pd.DataFrame:
    """Similar to run except without @hydra.main function decorator.

    Args:
        cfg (DictConfig):
            OmegaConfig Dictionary containing configurable parameters
            for evaluating phonemes.

    Returns:
        output_complete (pd.DataFrame):
            DataFrame appended with ACR, MCD, WER and CER metrics.
    """

    logging.info("Generate metrics...")
    path_dict = {
        "combined": cfg.path.combined_path,
        "gt_wav_dir": cfg.path.gt_wav_dir,
        "gt_mel_dir": cfg.path.gt_mel_dir,
        "gt_mfcc_dir": cfg.path.gt_mfcc_dir,
        "syn_path": cfg.path.syn_path,
        "syn_wav_path": cfg.path.syn_wav_path,
        "syn_mel_dir": cfg.path.syn_mel_dir,
        "syn_mfcc_dir": cfg.path.syn_mfcc_dir,
        "original": cfg.path.test_csv_path,
        "mfcc": cfg.path.test_mfcc_path,
        "acr": cfg.path.test_acr_path,
        "mcd": cfg.path.test_mcd_path,
        "asr": cfg.path.test_asr_path,
        "wer_cer": cfg.path.test_wer_cer_path,
        "complete": cfg.path.test_complete_path,
    }

    mel_mfcc_dict = {
        "sr": cfg.mel_mfcc.sampling_rate,
        "n_fft": cfg.mel_mfcc.n_fft,
        "hop_length": cfg.mel_mfcc.hop_length,
        "win_length": cfg.mel_mfcc.win_length,
        "window": cfg.mel_mfcc.window,
        "power": cfg.mel_mfcc.power,
        "n_mels": cfg.mel_mfcc.n_mels,
        "n_mfcc": cfg.mel_mfcc.n_mfcc,
        "dct_type": cfg.mel_mfcc.dct_type,
        "norm_mfcc": cfg.mel_mfcc.norm_mfcc,
        "lifter": cfg.mel_mfcc.lifter,
    }

    # Text type to be used for ACR computation. 'term' columm for unnormalized text;
    # and 'norm_term' column for normalized text
    text_type = "term" if cfg.file_name in ["ipa_en", "ipa_ms", "en_en_un", "ms_en_un"] else "norm_term"

    # Initialize pandarallel
    progress_bar = cfg.general.progress_bar
    num_proc = cfg.general.nb_workers
    initialize_pandarallel(progress_bar, num_proc)

    # Load output csv file and configure DataFrame
    output_meta = load_csv(path_dict)

    # Generate mel and mfcc of speech generated by Malaya VITS (ground truth)
    output_mfcc_gt = append_mel_mfcc_path(output_meta, path_dict, mel_mfcc_dict, "gt")

    # Generate mel and mfcc of synthesized speech
    output_mfcc = append_mel_mfcc_path(output_mfcc_gt, path_dict, mel_mfcc_dict)
    save_to_csv(output_mfcc, path_dict["mfcc"])

    # Append Alignment Coverage Ratio (ACR)
    output_acr = append_alignment_score(output_mfcc, text_type=text_type)
    save_to_csv(output_acr, path_dict["acr"])

    # Append Mel-Ceptral Distortion (MCD)
    output_mcd = append_mcd(output_acr)
    save_to_csv(output_mcd, path_dict["mcd"])

    # Generate transcribed text
    output_asr_syn = append_asr(output_mcd, "syn_transcribed")
    save_to_csv(output_asr_syn, path_dict["asr"])

    # Append Word Error Rate (WER) & Character Error Rate (CER)
    output_wer_cer = append_wer_cer(output_asr_syn, "syn_transcribed")
    save_to_csv(output_wer_cer, path_dict["wer_cer"])

    # Append PCA
    output_complete = append_pca(output_wer_cer)
    save_to_csv(output_complete, path_dict["complete"])

    return output_complete


def initialize_pandarallel(progress_bar, num_proc: int):
    """Initialize pandarallel"""
    return pandarallel.initialize(progress_bar=progress_bar, nb_workers=num_proc)


def load_csv(
    path_dict: Dict[str, str],
) -> pd.DataFrame:
    """Load output csv file and amend DataFrame structure required
    for speech quality features calculation.

    Args:
        path_dict (Dict[str, str]):
            Dictionaries containing file paths.

    Returns:
        pd.DataFrame:
            Configured DataFrame.
    """

    # Load csv file
    logger.info("Loading csv file...")
    df = pd.read_csv(path_dict["original"])

    # Append id (i.e. wav file name)
    logger.info("Appending 'id' column...")
    id_list = df["syn_wav_path"].parallel_map(lambda x: x.rsplit("/")[-1].replace(".wav", "")).to_list()
    df.insert(0, "id", id_list)

    # Set id to be integer type
    df["id"] = df["id"].astype("int32")
    logger.info("Successfully appended 'id' column.")

    # Append gaming terms (i.e. 'term', 'norm_term', and 'custom_norm_term') to DataFrame
    logger.info("Appending gaming terms from `combined_gaming_terms.csv`...")
    combined = pd.read_csv(path_dict["combined"])

    for text_type in ["custom_norm_term", "norm_term", "term"]:
        text_list = df["id"].parallel_map(lambda x: combined.loc[combined["id"] == x, text_type].item()).to_list()
        df.insert(3, text_type, text_list)
        logger.info("Successfully appended '%s' column.", text_type)

    # Append absolute path to ground truth wav file
    logger.info("Appending 'gt_wav_path' column...")
    df.insert(2, "gt_wav_path", df["id"].parallel_map(lambda x: f"{path_dict['gt_wav_dir']}/{x}.wav"))

    # Append ground truth mel and mfcc path
    logger.info("Appending 'gt_mel_path' column...")
    df["gt_mel_path"] = df["id"].parallel_map(lambda x: f"{path_dict['gt_mel_dir']}/{x}.npy")
    logger.info("Successfully appended 'gt_mel_path' columns.")

    logger.info("Appending 'gt_mfcc_path' column...")
    df["gt_mfcc_path"] = df["id"].parallel_map(lambda x: f"{path_dict['gt_mfcc_dir']}/{x}.npy")
    logger.info("Successfully appended 'gt_mfcc_path' column.")

    # Amend path in syn_wav_path to local environment
    logger.info("Appending 'syn_wav_path' column...")
    df["syn_wav_path"] = df["id"].parallel_map(lambda x: f"{path_dict['syn_wav_path']}/{x}.wav")
    logger.info("Successfully appended 'syn_wav_path' column.")

    # Create DataFrame folder if not exist
    dataframe_dir = Path(path_dict["syn_path"]).joinpath("dataframe")

    if not dataframe_dir.is_dir():
        dataframe_dir.mkdir(parents=True, exist_ok=False)

    return df


def gen_gt_csv(
    cfg: DictConfig,
) -> pd.DataFrame:
    """Generate basic DataFrame for audio files generated by Malaya VITS model.

    Args:
        cfg (DictConfig):
            OmegaConfig dictionary containing configurables
            from `model_objective_eval.yaml`

    Returns:
        df_term (pd.DataFrame):
            Configured DataFrame.
    """

    # Load combined gaming terms csv file
    logger.info("Loading `combined_gaming_terms.csv file...")
    df = pd.read_csv(cfg.path.combined_path)

    # Drop phonemes columns since Malaya VITS do not need phonemes to generate audio
    # custom_norm_term is specifically meant for Malaya VITS model and not applicable to espeak
    df_term = df.loc[:, ["id", "term", "norm_term", "custom_norm_term"]]
    logger.info("Discard columns related to phonemes")

    # Append ground truth path
    logger.info("Appending 'gt_wav_path' column...")
    df_term["gt_wav_path"] = df_term["id"].parallel_map(lambda x: f"{cfg.path.gt_wav_dir}/{x}.wav")
    logger.info("Successfully appended 'gt_wav_path' column.")

    # Initialize dictionary for mel and mfcc generation
    logger.info("Generating mel and mfcc...")

    path_dict = {
        "gt_mel_dir": cfg.path.gt_mel_dir,
        "gt_mfcc_dir": cfg.path.gt_mfcc_dir,
    }

    mel_mfcc_dict = {
        "sr": cfg.mel_mfcc.sampling_rate,
        "n_fft": cfg.mel_mfcc.n_fft,
        "hop_length": cfg.mel_mfcc.hop_length,
        "win_length": cfg.mel_mfcc.win_length,
        "window": cfg.mel_mfcc.window,
        "power": cfg.mel_mfcc.power,
        "n_mels": cfg.mel_mfcc.n_mels,
        "n_mfcc": cfg.mel_mfcc.n_mfcc,
        "dct_type": cfg.mel_mfcc.dct_type,
        "norm_mfcc": cfg.mel_mfcc.norm_mfcc,
        "lifter": cfg.mel_mfcc.lifter,
    }

    df_term = append_mel_mfcc_path(df_term, path_dict, mel_mfcc_dict, "gt")
    save_to_csv(df_term, cfg.path.gt_basic_path)
    logger.info("Successfully appended 'gt_mel_path' and 'gt_mfcc_path' columns.")

    return df_term


def poor_vs_good_phon(gaming_dir: str, phon_set: str, feature: str, num: int = 2, choice: str = "both") -> pd.DataFrame:
    """Generate list of num lowest and highest quality speech by speech features
    for selected phoneme set.

    Args:
        gaming_dir (str):
            Absolute path to directory holding different phoneme sets.
        phon_set (str):
            Name of phoneme set either 'eng2ipa_n', 'ipa_en', 'ipa_norm_en', 'ipa_ms', 'ipa_norm_ms',
            'en_en_un', 'ms_en_un', 'en_en_n', or 'ms_en_n',
        feature (str):
            Feature to evaluate speech quality. Either
            syn_acr, mcd, syn_wer, or syn_cer.
        num (int):
            Top n number of lowest and highest speech quality.
        choice (str):
            Either "both" (i.e. highest and lowest audio quality),
            "highest" (i.e. only highest audio quality) or
            "lowest" (i.e. only lowest audio quality) (Default: "both").

    Returns:
        (List[str]):
            List containing ids of 'num' lowest and/or highest 'num' speech quality.
    """

    # Get absolute path to evalutation DataFrame
    eval_path = Path(gaming_dir).joinpath(phon_set, f"output_{phon_set}_complete.csv")

    # Read Evaluation DataFrame
    df_eval = pd.read_csv(eval_path)

    # Ensure correct type of text used for display i.e. unnormalized text should use
    # "term" and normalized text should used "norm_term"
    text_type = "term" if phon_set in ["ipa_en", "ipa_ms", "en_en_un", "ms_en_un"] else "norm_term"

    if choice == "both":
        logger.info("Generating list of %d lowest and highest quality speech by %s...", num, feature)

    else:
        logger.info("Generating list of %d %s quality speech by %s...", num, choice, feature)

    # Generate 'lowest' DataFrame containing audio file of lowest quality
    # and 'highest' DataFrame containing audio file of highest quality
    speech_dict = gen_top_bottom(df_eval, feature, num)

    if choice == "both":
        # Display both lowest and highest quality audio files
        display_audio(speech_dict, num, feature, text_type)

        # Concatenate both lowest and highest DataFrame row-wise
        df = pd.concat([speech_dict["lowest"], speech_dict["highest"]], axis=0).reset_index(drop=True)

        # Return list of id for lowest and highest audio files
        return df.loc[:, "id"].to_list()

    # Display only lowest or highest quality audio files
    display_audio({choice: speech_dict[choice]}, num, feature, text_type)

    # Return list of id for lowest or highest audio files depending on choice
    return speech_dict[choice].loc[:, "id"].to_list()


if __name__ == "__main__":
    run()
